tf-idf : 텍스트 데이터(검색어)를 단어 단위로 쪼개고 문서(DB에서 해당하는 컬럼)에 단어 중요도를 수치로 표현
bert : 문서 속에 문장/단어의 의미를 벡터로 표현

* 음식점 검색 알고리즘 코드 흐름
: 검색 -> 전처리 -> 벡터화 -> 검색어 해석 -> 유사도 점수 계산 -> 정렬 -> 결과 도출

※유사도 점수 계산
: final = 메뉴tf-idf유사도*0.45 + 태그tf-idf유사도*0.1+버트유사도*0.25 + 리뷰와커뮤니티tf-idf유사도*0.2+메뉴빈도수*1.2+리뷰와커뮤니티 빈도수*1
-메뉴 직접 매칭(α) > BERT 의미 매칭(γ) > 상황/조건(δ) > 태그 보조(β)
  → 실제 사용자가 원하는 건 “정확한 음식”이고, 의미적 확장은 보조일 뿐.
-보너스 계수는 “문자 그대로 단어가 있으면 그 자체로 큰 증거”이므로 크게 설정.

| 모델/기법                    | 역할                       | 강점                 | 한계                 |
| -------------------------- | ------------               | ------------------ | ------------------ |
| TF-IDF                        | 단어 빈도 기반 벡터화 | 빠르고 명확한 키워드 매칭     | 의미 이해 부족           |
| Sentence-BERT (MiniLM) | 의미 기반 임베딩        | 유사 의미도 잡아냄, 다국어 지원 | 연산량 많음, 도메인 최적화 부족 |
| Okt (형태소 분석)          | 한국어 명사 추출        | 조사 제거, 핵심 키워드만 남김  | 신조어/브랜드 인식 약함      |
| cosine_similarity            | 벡터 간 유사도 계산    | 간단하고 효과적           | 벡터 품질에 의존          |

* 피드 검색 알고리즘 코드 흐름
: 검색 -> 후보 정렬 -> 유사도 점수 계산 -> 정렬 -> 결과 도출

Okt: 한국어 텍스트를 잘게 쪼개서 검색어/본문에서 명사 추출
BERT (SentenceTransformer): 추출된 텍스트와 질의를 의미적 벡터 공간에 매핑 → cosine similarity로 의미 유사도 계산

※“분위기 좋은” ↔ “무드 좋은/감성/조용한/데이트 코스/아늑한”처럼 표현 다양성을 자연스럽게 잡음.
해시태그/본문 전반에서 의미적으로 가까운 문서를 잘 올려줌(문장형 질의에 강함).